{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK255E7YoEIt"
   },
   "source": [
    "# DeepLabCut Toolbox Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jqLZhp7EoEI0"
   },
   "outputs": [],
   "source": [
    "import deeplabcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_config_file = '/DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12/config.yaml'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Uoz9mdPoEIy"
   },
   "source": [
    "## Create a new project\n",
    "\n",
    "Note: Run this one the first time to create a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9DjG55FoEI7"
   },
   "outputs": [],
   "source": [
    "# deeplabcut.create_new_project(\n",
    "#     'Bird Pose',\n",
    "#     'd22cs051',\n",
    "#     ['/DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/videos/vid1.mp4',\n",
    "#      '/DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/videos/vid2.mp4',\n",
    "#      '/DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/videos/vid3.mp4'],\n",
    "#     working_directory='/DATA1/bikash_dutta/DL/Project/DeepCutLab/birds', \n",
    "#     copy_videos=True,\n",
    "#     multianimal=False\n",
    "#     )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, go edit the config.yaml file that was created! \n",
    "Add your body part labels, edit the number of frames to extract per video, etc. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0yXW0bx1oEJA"
   },
   "source": [
    "## Extract frames from videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1ulumCuoEJC"
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "#there are other ways to grab frames, such as uniformly; please see the paper:\n",
    "\n",
    "# #AUTOMATIC:\n",
    "# deeplabcut.extract_frames(\n",
    "#     path_config_file,\n",
    "#     mode='mannual',\n",
    "#     algo='kmeans',\n",
    "#     crop=False,\n",
    "#     userfeedback=True,\n",
    "#     cluster_step=1,\n",
    "#     cluster_resizewidth=30,\n",
    "#     cluster_color=False,\n",
    "#     opencv=True,\n",
    "#     slider_width=25,\n",
    "#     config3d=None,\n",
    "#     extracted_cam=0,\n",
    "#     videos_list=videos,\n",
    "# )\n",
    "# deeplabcut.extract_frames(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #AND/OR:\n",
    "# #SELECT RARE EVENTS MANUALLY:\n",
    "# %gui wx\n",
    "# deeplabcut.extract_frames(path_config_file,'manual')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gjn6ZDonoEJH"
   },
   "source": [
    "## Label the extracted frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iyROSOiEoEJI"
   },
   "outputs": [],
   "source": [
    "# note run this on ipython with gui to lable your data\n",
    "# deeplabcut.label_frames(path_config_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vim95ZvkPSeN"
   },
   "source": [
    "## Check the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NwvgPJouPP2O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by d22cs051.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:02<00:00,  7.42it/s]\n",
      "100%|██████████| 19/19 [00:07<00:00,  2.67it/s]\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.check_labels(path_config_file) #this creates a subdirectory with the frames + your labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "of87fOjgPqzH"
   },
   "source": [
    "If the labels need adjusted, you can use relauch the labeling GUI to move them around, save, and re-plot!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNi9s1dboEJN"
   },
   "source": [
    "## Create a training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMeUwgxPoEJP",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading a ImageNet-pretrained model from http://download.tensorflow.org/models/resnet_v1_50_2016_08_28.tar.gz....\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([35, 34, 42, 27, 11,  2, 33, 45, 22, 48,  4, 10, 29, 40, 32, 41, 37,\n",
       "           7, 14, 31, 28, 56, 52, 18, 54, 26, 15,  5, 30, 16, 49, 20, 50,  8,\n",
       "          13, 25, 17, 43, 46, 51, 38,  1, 12, 57, 24,  6, 23, 36, 21, 19,  9,\n",
       "          39, 55,  3,  0]),\n",
       "   array([53, 47, 44])))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file)\n",
    "#remember, there are several networks you can pick, the default is resnet-50!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4FczXGDoEJU"
   },
   "source": [
    "## Start training:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pOvDq_2oEJW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7]],\n",
      " 'all_joints_names': ['beeak',\n",
      "                      'head',\n",
      "                      'body',\n",
      "                      'right_wing',\n",
      "                      'left_wing',\n",
      "                      'tail',\n",
      "                      'right_leg',\n",
      "                      'left_leg'],\n",
      " 'alpha_r': 0.02,\n",
      " 'apply_prob': 0.5,\n",
      " 'batch_size': 1,\n",
      " 'contrast': {'clahe': True,\n",
      "              'claheratio': 0.1,\n",
      "              'histeq': True,\n",
      "              'histeqratio': 0.1},\n",
      " 'convolution': {'edge': False,\n",
      "                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},\n",
      "                 'embossratio': 0.1,\n",
      "                 'sharpen': False,\n",
      "                 'sharpenratio': 0.3},\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Bird '\n",
      "            'PoseMay12/Bird Pose_d22cs05195shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'decay_steps': 30000,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/home/planck/anaconda3/envs/bikash/lib/python3.10/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'lr_init': 0.0005,\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Bird '\n",
      "                'PoseMay12/Documentation_data-Bird Pose_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_stage': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 8,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': '/DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird '\n",
      "                 'Pose-d22cs051-2023-05-12',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird '\n",
      "                    'Pose-d22cs051-2023-05-12/dlc-models/iteration-0/Bird '\n",
      "                    'PoseMay12-trainset95shuffle1/train/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Batch Size is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/planck/anaconda3/envs/bikash/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "2023-05-12 05:36:19.078171: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-05-12 05:36:19.078221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22086 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ImageNet-pretrained resnet_50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 05:36:19.418158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22086 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-05-12 05:36:20.062212: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
      "2023-05-12 05:36:21.099379: W tensorflow/c/c_api.cc:300] Operation '{name:'pose/locref_pred/block4/biases/Momentum/Assign' id:6191 op device:{requested: '', assigned: ''} def:{{{node pose/locref_pred/block4/biases/Momentum/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](pose/locref_pred/block4/biases/Momentum, pose/locref_pred/block4/biases/Momentum/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': '/DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12/dlc-models/iteration-0/Bird PoseMay12-trainset95shuffle1/train/snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7]], 'all_joints_names': ['beeak', 'head', 'body', 'right_wing', 'left_wing', 'tail', 'right_leg', 'left_leg'], 'alpha_r': 0.02, 'apply_prob': 0.5, 'contrast': {'clahe': True, 'claheratio': 0.1, 'histeq': True, 'histeqratio': 0.1, 'gamma': False, 'sigmoid': False, 'log': False, 'linear': False}, 'convolution': {'edge': False, 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]}, 'embossratio': 0.1, 'sharpen': False, 'sharpenratio': 0.3}, 'cropratio': 0.4, 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Bird PoseMay12/Bird Pose_d22cs05195shuffle1.mat', 'decay_steps': 30000, 'display_iters': 1000, 'init_weights': '/home/planck/anaconda3/envs/bikash/lib/python3.10/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt', 'lr_init': 0.0005, 'max_input_size': 1500, 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Bird PoseMay12/Documentation_data-Bird Pose_95shuffle1.pickle', 'min_input_size': 64, 'multi_stage': False, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 8, 'pos_dist_thresh': 17, 'project_path': '/DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': (-90, 90)}}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 05:36:23.978153: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-05-12 05:36:24.515991: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-05-12 05:36:24.516388: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-05-12 05:36:24.516405: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-05-12 05:36:24.516839: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-05-12 05:36:24.516882: W tensorflow/compiler/xla/stream_executor/gpu/redzone_allocator.cc:317] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "iteration: 1000 loss: 0.0221 lr: 0.005\n",
      "iteration: 2000 loss: 0.0156 lr: 0.005\n",
      "iteration: 3000 loss: 0.0134 lr: 0.005\n",
      "iteration: 4000 loss: 0.0129 lr: 0.005\n",
      "iteration: 5000 loss: 0.0124 lr: 0.005\n",
      "iteration: 6000 loss: 0.0121 lr: 0.005\n",
      "iteration: 7000 loss: 0.0112 lr: 0.005\n",
      "iteration: 8000 loss: 0.0109 lr: 0.005\n",
      "iteration: 9000 loss: 0.0103 lr: 0.005\n",
      "iteration: 10000 loss: 0.0102 lr: 0.005\n",
      "iteration: 11000 loss: 0.0110 lr: 0.02\n",
      "iteration: 12000 loss: 0.0104 lr: 0.02\n",
      "iteration: 13000 loss: 0.0097 lr: 0.02\n",
      "iteration: 14000 loss: 0.0088 lr: 0.02\n",
      "iteration: 15000 loss: 0.0082 lr: 0.02\n",
      "iteration: 16000 loss: 0.0076 lr: 0.02\n",
      "iteration: 17000 loss: 0.0073 lr: 0.02\n",
      "iteration: 18000 loss: 0.0068 lr: 0.02\n",
      "iteration: 19000 loss: 0.0065 lr: 0.02\n",
      "iteration: 20000 loss: 0.0062 lr: 0.02\n",
      "iteration: 21000 loss: 0.0061 lr: 0.02\n",
      "iteration: 22000 loss: 0.0054 lr: 0.02\n",
      "iteration: 23000 loss: 0.0055 lr: 0.02\n",
      "iteration: 24000 loss: 0.0052 lr: 0.02\n",
      "iteration: 25000 loss: 0.0050 lr: 0.02\n",
      "iteration: 26000 loss: 0.0048 lr: 0.02\n",
      "iteration: 27000 loss: 0.0047 lr: 0.02\n",
      "iteration: 28000 loss: 0.0045 lr: 0.02\n",
      "iteration: 29000 loss: 0.0044 lr: 0.02\n",
      "iteration: 30000 loss: 0.0042 lr: 0.02\n",
      "iteration: 31000 loss: 0.0041 lr: 0.02\n",
      "iteration: 32000 loss: 0.0040 lr: 0.02\n",
      "iteration: 33000 loss: 0.0039 lr: 0.02\n",
      "iteration: 34000 loss: 0.0040 lr: 0.02\n",
      "iteration: 35000 loss: 0.0040 lr: 0.02\n",
      "iteration: 36000 loss: 0.0038 lr: 0.02\n",
      "iteration: 37000 loss: 0.0036 lr: 0.02\n",
      "iteration: 38000 loss: 0.0038 lr: 0.02\n",
      "iteration: 39000 loss: 0.0036 lr: 0.02\n",
      "iteration: 40000 loss: 0.0036 lr: 0.02\n",
      "iteration: 41000 loss: 0.0034 lr: 0.02\n",
      "iteration: 42000 loss: 0.0034 lr: 0.02\n",
      "iteration: 43000 loss: 0.0033 lr: 0.02\n",
      "iteration: 44000 loss: 0.0031 lr: 0.02\n",
      "iteration: 45000 loss: 0.0032 lr: 0.02\n",
      "iteration: 46000 loss: 0.0031 lr: 0.02\n",
      "iteration: 47000 loss: 0.0031 lr: 0.02\n",
      "iteration: 48000 loss: 0.0030 lr: 0.02\n",
      "iteration: 49000 loss: 0.0030 lr: 0.02\n",
      "iteration: 50000 loss: 0.0030 lr: 0.02\n",
      "iteration: 51000 loss: 0.0029 lr: 0.02\n",
      "iteration: 52000 loss: 0.0030 lr: 0.02\n",
      "iteration: 53000 loss: 0.0028 lr: 0.02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m deeplabcut\u001b[39m.\u001b[39;49mtrain_network(path_config_file)\n",
      "File \u001b[0;32m~/anaconda3/envs/bikash/lib/python3.10/site-packages/deeplabcut/pose_estimation_tensorflow/training.py:223\u001b[0m, in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[1;32m    212\u001b[0m         train(\n\u001b[1;32m    213\u001b[0m             \u001b[39mstr\u001b[39m(poseconfigfile),\n\u001b[1;32m    214\u001b[0m             displayiters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m             allow_growth\u001b[39m=\u001b[39mallow_growth,\n\u001b[1;32m    220\u001b[0m         )  \u001b[39m# pass on path and file name for pose_cfg.yaml!\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 223\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    224\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     os\u001b[39m.\u001b[39mchdir(\u001b[39mstr\u001b[39m(start_path))\n",
      "File \u001b[0;32m~/anaconda3/envs/bikash/lib/python3.10/site-packages/deeplabcut/pose_estimation_tensorflow/training.py:212\u001b[0m, in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mdeeplabcut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpose_estimation_tensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrain\u001b[39;00m \u001b[39mimport\u001b[39;00m train\n\u001b[1;32m    211\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSelecting single-animal trainer\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 212\u001b[0m         train(\n\u001b[1;32m    213\u001b[0m             \u001b[39mstr\u001b[39;49m(poseconfigfile),\n\u001b[1;32m    214\u001b[0m             displayiters,\n\u001b[1;32m    215\u001b[0m             saveiters,\n\u001b[1;32m    216\u001b[0m             maxiters,\n\u001b[1;32m    217\u001b[0m             max_to_keep\u001b[39m=\u001b[39;49mmax_snapshots_to_keep,\n\u001b[1;32m    218\u001b[0m             keepdeconvweights\u001b[39m=\u001b[39;49mkeepdeconvweights,\n\u001b[1;32m    219\u001b[0m             allow_growth\u001b[39m=\u001b[39;49mallow_growth,\n\u001b[1;32m    220\u001b[0m         )  \u001b[39m# pass on path and file name for pose_cfg.yaml!\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    223\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/anaconda3/envs/bikash/lib/python3.10/site-packages/deeplabcut/pose_estimation_tensorflow/core/train.py:283\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep, keepdeconvweights, allow_growth)\u001b[0m\n\u001b[1;32m    280\u001b[0m     current_lr \u001b[39m=\u001b[39m lr_gen\u001b[39m.\u001b[39mget_lr(it \u001b[39m-\u001b[39m start_iter)\n\u001b[1;32m    281\u001b[0m     lr_dict \u001b[39m=\u001b[39m {learning_rate: current_lr}\n\u001b[0;32m--> 283\u001b[0m [_, loss_val, summary] \u001b[39m=\u001b[39m sess\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m    284\u001b[0m     [train_op, total_loss, merged_summaries], feed_dict\u001b[39m=\u001b[39;49mlr_dict\n\u001b[1;32m    285\u001b[0m )\n\u001b[1;32m    286\u001b[0m cum_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_val\n\u001b[1;32m    287\u001b[0m train_writer\u001b[39m.\u001b[39madd_summary(summary, it)\n",
      "File \u001b[0;32m~/anaconda3/envs/bikash/lib/python3.10/site-packages/tensorflow/python/client/session.py:968\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m run_metadata_ptr \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_NewBuffer() \u001b[39mif\u001b[39;00m run_metadata \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(\u001b[39mNone\u001b[39;49;00m, fetches, feed_dict, options_ptr,\n\u001b[1;32m    969\u001b[0m                      run_metadata_ptr)\n\u001b[1;32m    970\u001b[0m   \u001b[39mif\u001b[39;00m run_metadata:\n\u001b[1;32m    971\u001b[0m     proto_data \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m~/anaconda3/envs/bikash/lib/python3.10/site-packages/tensorflow/python/client/session.py:1191\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[39m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[39m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[39mif\u001b[39;00m final_fetches \u001b[39mor\u001b[39;00m final_targets \u001b[39mor\u001b[39;00m (handle \u001b[39mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1191\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_run(handle, final_targets, final_fetches,\n\u001b[1;32m   1192\u001b[0m                          feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m   results \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/bikash/lib/python3.10/site-packages/tensorflow/python/client/session.py:1371\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1368\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1371\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m   1372\u001b[0m                        run_metadata)\n\u001b[1;32m   1373\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[0;32m~/anaconda3/envs/bikash/lib/python3.10/site-packages/tensorflow/python/client/session.py:1378\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_call\u001b[39m(\u001b[39mself\u001b[39m, fn, \u001b[39m*\u001b[39margs):\n\u001b[1;32m   1377\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m   1379\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOpError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1380\u001b[0m     message \u001b[39m=\u001b[39m compat\u001b[39m.\u001b[39mas_text(e\u001b[39m.\u001b[39mmessage)\n",
      "File \u001b[0;32m~/anaconda3/envs/bikash/lib/python3.10/site-packages/tensorflow/python/client/session.py:1361\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[1;32m   1359\u001b[0m   \u001b[39m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[1;32m   1360\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1361\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m   1362\u001b[0m                                   target_list, run_metadata)\n",
      "File \u001b[0;32m~/anaconda3/envs/bikash/lib/python3.10/site-packages/tensorflow/python/client/session.py:1454\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1452\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_tf_sessionrun\u001b[39m(\u001b[39mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1453\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1454\u001b[0m   \u001b[39mreturn\u001b[39;00m tf_session\u001b[39m.\u001b[39;49mTF_SessionRun_wrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session, options, feed_dict,\n\u001b[1;32m   1455\u001b[0m                                           fetch_list, target_list,\n\u001b[1;32m   1456\u001b[0m                                           run_metadata)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(path_config_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZygsb2DoEJc"
   },
   "source": [
    "## Start evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nv4zlbrnoEJg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7]],\n",
      " 'all_joints_names': ['beeak',\n",
      "                      'head',\n",
      "                      'body',\n",
      "                      'right_wing',\n",
      "                      'left_wing',\n",
      "                      'tail',\n",
      "                      'right_leg',\n",
      "                      'left_leg'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Bird '\n",
      "            'PoseMay12/Bird Pose_d22cs05195shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/home/planck/anaconda3/envs/bikash/lib/python3.10/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 8,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird '\n",
      "                    'Pose-d22cs051-2023-05-12/dlc-models/iteration-0/Bird '\n",
      "                    'PoseMay12-trainset95shuffle1/test/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n",
      "/home/planck/anaconda3/envs/bikash/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  DLC_resnet50_Bird PoseMay12shuffle1_50000  with # of training iterations: 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 06:31:09.610752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22086 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58it [00:03, 18.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis is done and the results are stored (see evaluation-results) for snapshot:  snapshot-50000\n",
      "Results for 50000  training iterations: 95 1 train error: 2.99 pixels. Test error: 69.53  pixels.\n",
      "With pcutoff of 0.6  train error: 2.99 pixels. Test error: 25.58 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "Plotting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58/58 [00:16<00:00,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "Please check the results, then choose the best model (snapshot) for prediction. You can update the config.yaml file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise, consider adding more labeled-data and retraining the network (see DeepLabCut workflow Fig 2, Nath 2019)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1280x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(path_config_file, plotting=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVFLSKKfoEJk"
   },
   "source": [
    "## Start Analyzing videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_LZiS_0oEJl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7]],\n",
      " 'all_joints_names': ['beeak',\n",
      "                      'head',\n",
      "                      'body',\n",
      "                      'right_wing',\n",
      "                      'left_wing',\n",
      "                      'tail',\n",
      "                      'right_leg',\n",
      "                      'left_leg'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Bird '\n",
      "            'PoseMay12/Bird Pose_d22cs05195shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/home/planck/anaconda3/envs/bikash/lib/python3.10/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 8,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird '\n",
      "                    'Pose-d22cs051-2023-05-12/dlc-models/iteration-0/Bird '\n",
      "                    'PoseMay12-trainset95shuffle1/test/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n",
      "/home/planck/anaconda3/envs/bikash/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-50000 for model /DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12/dlc-models/iteration-0/Bird PoseMay12-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 06:31:50.258106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22086 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12/videos/vid1.mp4\n",
      "Loading  /DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12/videos/vid1.mp4\n",
      "Duration of video [s]:  10.08 , recorded with  25.0 fps!\n",
      "Overall # of frames:  252  found with (before cropping) frame dimensions:  1280 720\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 252/252 [00:08<00:00, 30.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12/videos...\n",
      "Starting to analyze %  /DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12/videos/vid2.mp4\n",
      "Loading  /DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12/videos/vid2.mp4\n",
      "Duration of video [s]:  37.96 , recorded with  25.0 fps!\n",
      "Overall # of frames:  949  found with (before cropping) frame dimensions:  1280 720\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 949/949 [00:18<00:00, 51.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12/videos...\n",
      "Starting to analyze %  /DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12/videos/vid3.mp4\n",
      "Loading  /DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12/videos/vid3.mp4\n",
      "Duration of video [s]:  158.47 , recorded with  30.0 fps!\n",
      "Overall # of frames:  4754  found with (before cropping) frame dimensions:  1280 720\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4754/4754 [01:30<00:00, 52.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12/videos...\n",
      "Starting to analyze %  /DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12/videos/vid4.mp4\n",
      "Loading  /DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12/videos/vid4.mp4\n",
      "Duration of video [s]:  255.6 , recorded with  25.0 fps!\n",
      "Overall # of frames:  6390  found with (before cropping) frame dimensions:  1280 720\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6390/6390 [02:02<00:00, 52.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12/videos...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_resnet50_Bird PoseMay12shuffle1_50000'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videofile_path = ['/DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12/videos/vid1.mp4',\n",
    "                  '/DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12/videos/vid2.mp4',\n",
    "                  '/DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12/videos/vid3.mp4',\n",
    "                  '/DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12/videos/vid4.mp4'\n",
    "                  ] #Enter a folder OR a list of videos to analyze.\n",
    "\n",
    "deeplabcut.analyze_videos(path_config_file,videofile_path, videotype='.mp4')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCrUvQIvoEKD"
   },
   "source": [
    "## Create labeled video\n",
    "``deeplabcut.create_labeled_video(config, videos, videotype='avi', shuffle=1, trainingsetindex=0, filtered=False, save_frames=False, Frames2plot=None, delete=False, displayedbodyparts='all', codec='mp4v', outputframerate=None, destfolder=None, draw_skeleton=False, trailpoints=0, displaycropped=False)``\n",
    "So please check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deeplabcut.create_labeled_video?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aDF7Q7KoEKE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process video: /DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12/videos/vid1.mp4Starting to process video: /DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12/videos/vid3.mp4Starting to process video: /DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12/videos/vid2.mp4Starting to process video: /DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12/videos/vid4.mp4\n",
      "\n",
      "Loading /DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12/videos/vid1.mp4 and data.\n",
      "\n",
      "Loading /DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12/videos/vid2.mp4 and data.\n",
      "Loading /DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12/videos/vid3.mp4 and data.\n",
      "Loading /DATA1/bikash_dutta/DL/Project/DeepCutLab/birds/Bird Pose-d22cs051-2023-05-12/videos/vid4.mp4 and data.\n",
      "\n",
      "Duration of video [s]: 10.08, recorded with 25.0 fps!\n",
      "Overall # of frames: 252 with cropped frame dimensions: 1280 720\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/252 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of video [s]: 37.96, recorded with 25.0 fps!\n",
      "Overall # of frames: 949 with cropped frame dimensions: 1280 720\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/949 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of video [s]: 255.6, recorded with 25.0 fps!Duration of video [s]: 158.47, recorded with 30.0 fps!\n",
      "\n",
      "Overall # of frames: 6390 with cropped frame dimensions: 1280 720Overall # of frames: 4754 with cropped frame dimensions: 1280 720\n",
      "\n",
      "Generating frames and creating video.Generating frames and creating video.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 252/252 [00:01<00:00, 242.71it/s]]\n",
      "100%|██████████| 949/949 [00:05<00:00, 163.62it/s]s]\n",
      "100%|██████████| 4754/4754 [00:25<00:00, 185.65it/s]\n",
      "100%|██████████| 6390/6390 [00:31<00:00, 203.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True, True, True, True]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_labeled_video(path_config_file,videofile_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GTiuJESoEKH"
   },
   "source": [
    "## Plot the trajectories of the analyzed videos\n",
    "This function plots the trajectories of all the body parts across the entire video. Each body part is identified by a unique color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gX21zZbXoEKJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: unrecognized arguments: #for making interactive plots.\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib notebook #for making interactive plots.\n",
    "deeplabcut.plot_trajectories(path_config_file,videofile_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Demo-yourowndata.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "bikash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
